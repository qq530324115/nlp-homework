{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture-03 Gradient Descent and Dymanic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week, we need complete following tasks:\n",
    "+ Re-review the course online programming; \n",
    "+ Choose 1 - 2 books which you interested and keep reading; \n",
    "+ Answer the review questions\n",
    "+ Prepare the basic requirement of our 1st project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I Review the online programming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "       6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "       1.7800e+01, 3.9690e+02, 9.1400e+00])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data['data'], data['target']\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnX+QHOV557/PjhoxS3KMOO/dmQEhQdkikYW0x8YQ64ItkkKVw1BrDMgY4gpnB8dVwQWmNhZnzggfMUo2Z1Oxsc8YuyouXFiA5A1EF8t3J2zHuMBeeSXL4tBVOPHDAxXLQYuBXdBo97k/Znp3tqff7rdnuqd/zPdTpZrV/Oh+u3fn228/z/d9HlFVEEIIKQYDaQ+AEEJIfFDUCSGkQFDUCSGkQFDUCSGkQFDUCSGkQFDUCSGkQFDUCSGkQFDUCSGkQFDUCSGkQCzr9Q7f8pa36KpVq3q9W0IIyTX79u37laoOhb2v56K+atUqTE5O9nq3hBCSa0TkOZv3MfxCCCEFgqJOCCEFgqJOCCEFgqJOCCEFgqJOCCEFwsr9IiLPAjir5akDqrpBRDYC+DKANQAOAfiIqv409lGS2JiYqmF8z2G8OD2L0ytljG1eg9HhatrD6pi4j6eX54djX9xObXoWJRHMqaJSdiACHJupY0CA+WYfn0rZwbbL12J0uNrV/v0+CyC2czcxVcMdjx7CsZl627h7gdh0PmqK+nNoCDgAHAPwfQDPApgFMA7gUwDeBPA2VZ0zbWtkZERpaUyHiakabt11ELP1xV9P2SnhrivW5VLY4z6eXp4fjt1/O2E4A4It7zwTO/fVOtq/3z6dkgAK1OcXtbDTczcxVcPYwwdQn1uqq86AYPyq9V39LkRkn6qOhL0vSvjlCIDdqvotVd0D4A8B/FsAX1LVLwH4GoDVAN7TwXhJDxjfc7jtCzRbn8P4nsMpjag74j6eXp4fjt1/O2HU5xUPPPlCx/v322d9TpcIepTt+W3fK+juuHv1PYsi6h8C8GsR+aWIfBgNAQeAWvPxF83Hs70fFJEbRGRSRCaPHj3a+WhJV7w4PRvp+awT9/H08vxw7J2Pbc4QXbDZXpR9djK+oM/06ntmK+pfBXA1gD8CcBzAVwCI5z3u/9vOuKreq6ojqjoyNBS6ypUkxOmVcqTns07cx9PL88Oxdz62knilx357UfbZyfiCPtOr75mVqKvqX6jqw6p6P4AdAEpYnJmf0Xx0g0VH4h0iiYuxzWtQdkpLnis7pYVEUd6I+3h6eX44dv/thOEMCK654MyO9++3T6ckcAaWXig6PXdjm9c0YvQ+4+7V9yzU/SIi6wB8FsA/NN//ITSSo/8I4JcAPiYirwL4MBqJ0+8lNFbSJW6Spijul7iPp5fnh2Nfup2o7peRs07raP+msQPAtkcOYXq24Vg52enM7e1uP9PuFxF5KxpJ0HcCGATwFIBPqeoeEbkIwD1YtDT+iaoGWlvofiGE+JGm3TYPzjBb90voTF1VXwLwHw2v/QDAuujDI4SQRbyiWpuexa27DgJALKIadsEIcvRkRdRt4YpSQkjqJGnJdC8YtelZKBYvGBNTtYX3FMkZRlEnhKROkqJqc8EokjOMok4ISZ0kRdXmglEkZxhFnRCSOkmKqs0FY3S4iruuWIdqpQwBUK2UM5UkjULP29kRQoiXJC2ZY5vX+DpbvBeM0eFqLkXcC0WdEJIJkhLVoq3PCIOiTghJnLRLPhdlFm4DRZ0QkihJe9DJUpgoJYQkStFKPmcdztQJIYnQ2tXIjzwu7MkDFHVCSOzYdDXK48KePEBRJ4TETlhXo1ZLYdpJ1KJBUSeExE5QaKXaItxMosYPE6WEkNgxhVaqlTIe33rxEu84k6jxQlEnhMSO7bL/XlZHnJiqYeP2vVi9dTc2bt+7pEpjkWD4hRASO7arOE+vlH3dMXEnUfspzENRJ4Qkgs0qTtu6LN1SpCYYYVDUCSGp0au6LEVqghEGRZ0QYk0S9sNe1GXpVZgnCzBRSgixwqYtXKfbTTqBWaQmGGFQ1AkhVpji0tseOdTxNpO6UHgpUhOMMBh+IYRYYYo/T8/WMTFV60gge5nA7Jfyu5ypE0KsCIo/37Rjf0ehk35KYPYKijohxIqw+HMnoZMkG0576ZfFRxR1QogVo8NVrBh0At8TdYl/rxKYvYrdZwGKOiHEmtsvW9smwl5q07PWM+JeJTD7qcYME6WEEGtaFwuZml8IsPCazXL8XiQw+yl2z5k6ISQSo8NVPL71Yty9ZUPbrF0AqOf9WZgR9zJ2nzYUdUJIR/iFTryC7pL2jNgUu9907lDhkqcMvxCSQ7LSLcgbOtm4fW8ml+P71ZjZdO4Qdu6rFa5yI0WdkJyR5TKyvaq62Al+F6AiVm5k+IWQnJFlJ0eeluMXNXnKmTohOSPrYpSX5fhFrdzImTohOaOfnBxJUtTKjRR1QnJGUcWo1+QpVBQF6/CLiJwM4ACAtwO4R1X/TER+C8DXAJwP4FkAN6rqd5MYKCGkQa+6BfUDeQkVRSFKTP3TAM7wPPcAgJUAPgHgYwAeEpGVqvpKTOMjhPiQdzHKiiWziFiFX0TkPAA3A9jW8twwgPUAHlDVewB8DsC/AnBl/MMkhBSFfiqulQahoi4iAwDuA3APgJ+0vLS6+ej+Jn7RfDzbZxs3iMikiEwePXq0i+ESQvJOli2ZRcBmpn49gFUAvgHAvT86FYC3Bqc0H9tWCqvqvao6oqojQ0NDHQ6VEFIEsm7JzDs2MfUzAQyhkSR1uQ7A6c2f3Ti7K/hH4hkaIaSIFNUfnhVsRP1BAD9v/rwWjbj6dwDcBuDrAD4gIofQSJS+CmBn/MMkhBSFOEsJMOHaTqioq+pTAJ4CABH5VfPpZ1R1n4h8EI14++cAPAfgalWdTmqwhJD8E5clM8s1cNJEVE3FMpNhZGREJycne7pPQkjxMFWErFbKeHzrxSmMKFlEZJ+qjoS9j7VfCOkTihaqYMLVH5YJIKQPKKI3nDVw/KGoE9IHFM0bPjFVw8zxE23PswYOwy+E5B6bsIqpSXQeQxXeBKlLpexg2+Vrcx1SigOKOiE5ZWKqhjsePYRjM/WF5/wcIBNTNd+G0EA+QxV+dx0AcMryZX0v6ADDL4TkEne22iroLt6wyview76CLkAuQxVMkAZDUSckh5hmqy6tAmcSO0U+/dxMkAZDUSckh4TNSlsFLkjsVm3djY3b9+bKBcMmIcFQ1ElfMzFVw8bte7E6Z+IWJNRegRvbvAZOSYzvr03P4qYd+zH8me/m4viL2rEoLpgoJX1LnpeZ+9VPAQIcIBYLx4/N1HHrroOYfO5lPPb00UwvUsp7k5AkoaiTviXIu511wYhSP2V8z2HU5+3KgczW5/DNJ55fuAbk6UJHGjD8QvqWvLsoRoerGNu8BqdXynhxehbjew77hk+iHo9X/vO8SKkf4Uyd9C15r+ttGz4yHWcUur3QFa3uTJbhTJ30LVl3UYQlcW2X/vsdZ1S6udAVse5MlqGok74lyy4KGyE0zZ5r07NLLgLe4xx0BiBmM0wb3V7oilZ3Jusw/EL6mqy6KGySuJVBx3dFKdAeinH/3TZxEPc/8XzgvqW57emZeiyhkrznLvIGRZ2QDGIjhGH9bfycPA88+ULovhXAG/V5fH7LhlgueHnPXeQNhl8IySA2S+FfmfWfpbfivTjMWXY6izM8kvXcRdGgqBOSQWyE0Gam631PKUIwPa7wSJZzF0WE4RdCMojN4iLTqlIXv9nwNRecGRpTd4kzPJLV3EURoagTklHChLBV+GvTsxBZjLOvGHRw+2Xt5QLuHF2Hb/+0htePmys8Au0XBPrM8wNFnZAMEyamo8NVTD73cmNpf0u4/I36vHGbMyGCLgDef/7iBWViqoaxhw+gPtfYQW16FmMPH1jYP8kWFHVCMorNitGJqdqSWi0urYlOdyZfEsGc6sKjCQWw48cvYOSs0zA6XMUdjx5aEHSX+pzijkcPUdQzCBOlhGQUm0U7pq5GwOJFwLUTukJu44Cpz+vCfkxeeNPzJF04UyckQbqJRdt41YMcKiWRwO5Ipr6lNtsm2YWiTkhCdFKvvfUiMGAIk3i7Gvkt7BGEz8jD5uvufiplB9M+nvhK2QnZAkkDhl8ISYioNU+89V78RFkAbDp3aOH/fn52AfCuc05DhPIubTgDsuB+2Xb5WjgD0vb6tsvXdrEHkhQUdUISImrNk7Bm0kBjdr1zX81YrKtaKePzWzbg2X+ZDZyJl50SVgz6z7RFgPGr1i/cTYwOVzF+1fol+2h9nWQLhl8ISYioNU9sY9jemi5+fvabd+wP3MbJzgAuPe+t2LmvtuRCUnZKXO2ZcyjqhCTE2OY1GHvowJJWcq1hDS9RmlmEXQDCtnVspo6d+2p4//lVYz9SN75fm55dklRli7tsQ1EnJEm8ge2AQPfY5jW4ecd+mx7RODUkSRlWQgBozPgfe/ooHt96cdtr3iSvyQdPUc8ejKkTkhDjew77LtoxJUpHh6u49sKVVtt+/fiJwM5B3li7Cb8Z/8RUDbc8eCA0vk/LYzahqBOSEEGdiUyCfOfoOmMCsxW/i4O3/R0APL71YhzZfimqFqV83W3cuuug1QIl1kPPJhR1QhIiSPT8enS6omy7UrP1ohHW/s62prmNA8f0WZINrERdRJ4UkVdFZEZEJkXkoubzoyLyTyLyhoh8T0RWJztcQvJDUMNnr1+9VZRtab1omDzxdzx6CBu378XNO/Zj+bIBrBh0AmuaB4VU3DAO66FnG9tE6Y8A/HcA/w7AfwVwX1PYvwXgKQBjAD4L4G8BXJTAOAnJHa7o3WSwF7phmNHhKrY9cshqhuzinSmbxPjYTH1h5j89W0fZKQW2qTO5Zkoi+G9X05ueB2zDL58A8CiA/w3gTQDzAK4BsBzAXar6BQDfBvB7InJOEgMlJK8EdRu6dddB3DZx0HcZvovfp//9ylOXWA8HLDsahbWpM4VpKOj5wXamfiqAo82fpwF8BMDVzf+7gcFfNB/PBvBMLKMjpAck1QDCJuk4W58LbAZtKpP7o2dexm0TB/H3B14KvCD4ERRisem4RLKNrai/BuASAOcC+CsAnwHwc8973KlC21+giNwA4AYAWLnSzrJFSC/opOiWLXc8ahdSCRJ902sK+NZRdymJ4DdPXuYr+GGuFbaeyzdW4RdVPaGq/7MZZvkxgE0A3OnFGc1H96/giM/n71XVEVUdGRoa8r5MSGpELboVhutgWbV1t7WLxRSeWTHoGK2IQHCVxTlViKCtEBddK8UnVNRFZLOIfE1EPiwi2wC8C8A/A7gfwHEAnxSRGwG8D8APVZWhF5IbohbdCqITB4tTElx49grf1y49760Y27ym42qLx2bqgDRK5AY5XkixsAm/vAzgAgAfRCNJ+kMAf66qL4nINQDGAfw1gCcBXJ/UQAlJgqhFt/xorZESlfqc4vFnXvZ97bGnj+LO0XWLPUhbXgtrcNG6/VffOBHoeCHFInSmrqo/UdV3qGpZVSuquklVf9J8bZeqnqOqy1X1Is7SSd6wXZRjopPZuS3u3cKdo+tw7YUrF8I0JRG865zTjB54L3OqvoudSDFhQS/S13Ti9rDpThQH7t3CbRMHl8zU51Tx0+dfaauwOHP8hDGOzwJc/QNFnaROUpZCW6K4PbxumTBBd8MkIkAU7XdKjRK9E1M1X5eLX4VF79i8sABXf8DaLyRVwmqWZA3b2ihASxei7ZfaBcBb0cX9mT7qFWm3MqPJTcMCXP1Bbmbqac/mSDIEWQqz+Pu1me36dQ+K0gADAOrzuvD3bqLiU83R3ad3xk4rY/+Qi5l63mZzxJ44LYW9wDTbLYkE2gY7EdTa9GxgM4zX3vCvqe7Xt5RWxv4hFzP1vM3miD1xWArjwHsnuOncId82b34dhYL6erZu19aG6FISQVBJF3c277dfrgrtX3Ih6nmbzRF7TCLZy1CBX6mA+594fuF1v9IBNqHAsMQl0DhW0+tzqpgOWZXK7wDxkgtRz8psjsRPFgpI2SQ/W+8MbWfBYdstiSzYEk3x9jDXjAJYtXU3KmUH2y5fy9k5yUdMvdsFIoQEYTvbtXlfa0u5sMTonCp27qth07lDxoVE85bxmunZOsYeOsA8E8mHqDPxU1yykAS3veMLe5/3WGyYrc/h7w+8hJOd4K9i62pSE26MnfQ3uQi/AEz8FJUsJMH94vpebO4Mo3jYW7Gphz6v2vC7A1i9dbe1d530H7mYqZPikoUkuN+d4HUXrox8ZxjW3zNolh1G611C0B0D80wkNzN1UkyykgSP407QdCzVShmPb73Yyg3jh1sywGVs8xqMPXwA9bml83VnQJhnIhR1ki5ZsDQC9j71IMKOxc/pE1SEC2g0yrj9sqWuFvfnOx49tPBZul+IC0WdpEpalsZWEa8MOnhlpo755ms2PnV3G15hff/5Vez+2UsLzy1fFhzhvPS8t2LnvtqSC4G7SKkacC6C7ixYUqO/EU2obKiJkZERnZyc7Ok+Sf8RJGydhkGARaGdfO7lJcLfygCwcIEAGmGR3zh5GY7N1NtWlZad0hKvut/rd12xDkDnC56CVryS/CAi+1R1JPR9FHVSFFo7EJnEcXS4io3b9ybS1KJTKmUH+2+/xDiuStnBmyfmrYTatA03rk/yi62o0/1CCoG3A5Ff/fFbd/0Mw5/5bqYEHWhYGiemakb3zPRs3bo5dhbcRCRdKOqkENgt9Z8PTEqmyfiew5EdP35CbdoGrY79AxOlJPdMTNUyN/uOSm16FisGHTgDgnpLbYCyU8LJzoDvxej0StnXteNNvLKkRn9BUSeJ0CsHhht2KQJe4XZtioB/04tN5w75VpcsOwNYMehgeqZO90sfQlEnseNXytbPEhgHnS7NzwNvnmh4aEy2T9Oxz9bnAQg+v2UDxbwP6StRp3+3N9jWczH9PqL8noqcAAwr93vzjv1WnyX9Rd+Iei9nj/2OjQPD9PuYfO7lJTHhsN/TqWXHqiBWXgm6aIX1PS3yBY+Y6Rv3S9DskcSLjQNj2yOHfH8fDzz5gvXvaWKqhlfeKK6gA8GuFb8+A7afJcWlb2bq9O/2jrAaKBNTNePses6wGO7F6VlMTNWw7ZFDhZ6ZtxLmWvGrAWP7WVJc+mamTv9u7whrahJ0d2QqT1sZdDD20IG+EfSSiNXS/tHhKqY+fQnu3rKBTWQIgD4qE8CaGNkhqMnDdReu9PVZL1820DeC7lKtlLtKIpNiYVsmoG/CL1locJw2WREEU4JvxaCDO0fXYeSs0xZquJREMFuf68i2uGLQyewK0jAEWDhHnSaRSTbo9feub2bq/U6W7lRsxtJNJcU4qJQd1Ofm8frx7vZ/95YNuOXBA8ZcgR/eYmQuJRHf7bBYV3aJ83vHgl5kCVly/9g0Ek97UdH0bL1rQQcaxxok6H6t80zvDkoik2ySxveub8Iv/U7W3D9h7eOKIFQrBh0ADaGOUg7XVD7XNFNnsj+7pPG940y9T+iF+2diqoaN2/di9dbd2Lh9Lyamah1/fqCLJs1ZwCkJbr+sUbfFz0/u1m7xO1+m919zwZm+z9O6mF3ScN1R1PsEk1DEJQit9cwVi0k8W2H3fj5KDDprlEQwfuX6hTsRv3DT+8+vYue+mu/5MoWn7hxdFxq2Itki6e+dH0yU9hFJZuG77bgTFHKYV0Vl0IEq8MpsPXR5fJo4A4Lxq9aHnld2KOof4vrexWZpFJG3AbgXwHkATgLwBIA/VdVnRGQUwF8DOKP5/PWqeiTyaElPCItjd4MpRlibnsXG7XtD/6BNn59XxZHtlwJY+uXIAiINl0xr4+ltl6+18pNnLcdBkiPJ750fNonSKhphmtsBvB3AjQDuE5FrAHwLwFMAxgB8FsDfArgomaGSLFMxeML9/NZAu6/aNPseEMHqrbsxeFIpFjdKnKgCU5++pO15m+JxpuNl0pN0i01M/Ueq+m5V/aKqfhzAywDWArgGwHIAd6nqFwB8G8Dvicg5yQ2XZJGJqRpee+OE72t+vUL97Fym4lRzqlAgc4IONEIlrbiJ3pt27A+1saURayX9QehMXVWPuz+LyAiA0wDsBLC6+bSbCftF8/FsAM/EOEaSccb3HF7Sgi0MvxCDd8XvgMG+lyU2nTu08LPNYqnW4+YKZ5IU1j51EVkD4O8APItGCOZW71uaj23fRBG5AcANALBy5cpOxkkyTNQ4sDfE4I0/X3vhStz/xPNxDjERdvz4BYycdRpGh6tWi6W8x93rWCvpD6wsjSLy2wC+D+AEgItV9SUAbkL0jOaj+9fZlihV1XtVdURVR4aGhrwvk5wTJQ7sDTH4WSHzIOgAUJ/XhZBKmBuHoRXSK0JFXUTOBPA9AG8B8GUAF4jIB9BIkh4H8EkRuRHA+wD8UFUZeukzwpo1uGSxHEC3uHXeg5ZK0U9OeolN+OUcAO70+i73SVWVpgNmHA1b45MAro99hCTzuGIV1sDCz3+ddwvfgAhuMvQKFYDNn0nPCZ2pq+r3VFW8/5qv7VLVc1R1uapexFl6/zI6XMX+2y/BoOP/J+XWQfGSdwtfUDI322leUlRYJoDEymevOA9OaWkworUOipdWB0mWGRBg+bLoX5copRIIiQNWacw4WWlsYUtUq95jTx/t5fACMdUxB4B5BY6fmI+8TdefnuXfGSkWFPUMY7MysRdjiHpRiWLVy1JMPSxc0mk4JUvH2Al5m1j0Owy/ZJi0G1t0W3nRZvv9QJ7zBkn/DZD4oahnmLSLPiV5UZmYquGWhw7kJpnYaXV3kz+929rzvSLtiQWJDkU9w6RRYL+VJC8q43sOYy5CaQEXZ0Bwyknhnvi4ufbClVZe/FZM/vQ8zX7TnliQ6FDUM0zaRZ+SvKjYiIJ3diwA3rl6BSqDJ3W9/yhUK+UlDSpsmTnuX+QsT7PftCcWJDoU9Qxj06A5SZK8qNiIgncerwB+9MzLsTTIsA2ntB7v6HAVj2+9GHdv2WD1+WMzddy8Yz9WeUIseZr9pj2xINGh+yXjpF306WRnYGFW2doEolvGNq/BLQ8diByCiSsGH7SdaqUc6PQYHa4aV5Ga9tPqXAqqHe+2s8sKrCaZPyjqfYatPc2vlOybHfi0Tbj7/OTOn8W63VYGnQHM1KNt26+dnN85q3bQUs8NsYxtXuNbpndOteeWVRvSnliQaDD80kdESdD1Iu47OlzF4Tv/MLbtrRh0FsJU1124EitOWR74fpuwgumcdboS9sXp2YWwWknagzhZja2T/EBR7yOiCHWccd8w+16l7F8XJgrVShm3X7Z2IbTxzSeeD5xJV8rOksRnSWThXLSOz3TOHnv6qLHOTRBuLmF0uIp5Q92YLMbWSX6gqPcRUYQ6LtdD2N3BbRMHAys72lB2Sth07tDCfoDgmLkzIAu5ATcR6Bbm8o4v6JzNRgzteO8E6CwhSUBR7yNMYuEm6FqJy/Ww7ZFDxruDiakavtllQwzXEfTY00et6rJXK2WMX7V+IUZ8x6Pm8QHBwmsjvm6Axetcmpiq4fU32y2PdJaQbmGitI+IkqCLw/UwMVUzzsJfnJ7F+J7DXblZBIs12m+2cKN4k6ATUzUcmzGPD2ics7GHDrT1YK1Nz8InJN6GGvbr93sYkKUXlDSSk6zzkn8o6n2E++W85cEDbXXA/aoJdut6CEr4nd60DXbDqS2xeJNN0MUpCV5/8wRWb929IFZh41vAIN62fbG9x2nq9uReN9Io3AZko4Ac6R6GX/qA1kTl+J7DxsYOcSfogrY3tnlN17Hj6dn6QuLVL1zkavGKQQfQxvvduP5NO/YHXgRcd8v4nsOoz9mpt5+bBWgP4dic5zRcMHla6UrMUNQLjl+i0hQ1qBi6E3Wyz43b9xpDKysGnSVJym5onU16V99+fssG3L1lA349e6ItfBLGzn01TEzVIl3o5lTbzq1fjNz2YtZrF0yeVroSMwy/FBy/2ZdJ3l5740TXKxpN8WKXslNa6ILUGrd3LzadxNjd2eTjWy9eMnZ3LEEt58K2GRbW8aJYbLbRapMEFo/XlNvwcnql3NMYt+lY6cbJF5ypRyAv5VJbiSJI9Xnt+lbbFC8GwmvXdJM09ZtNBo3Fhtr0bEd3E66wm2ySwNLWeIPOQFsLQK9NsxfVHFnnpRhQ1C3JU7lUl4mpWuQ64N3eaofF0VsF/baJg7g5JLYNNASyUnaMzasB/9lkHIW/AESuzgi0X6BabZy37lrqzVcItvzOmW2F2/xsmknGuNMuIEfiQbSDW9NuGBkZ0cnJyZ7uMw42bt/rKxJ+tUKygmnMgoZzxM9u2O3xmPbp3fbEVA0379gfOju3tQOuGHQWwjpuOCcOvGP27jtKyCjsvLuOnBenZ1EZdIx2SwFwZPul0Q6E5B4R2aeqI2Hv40zdkjwmkUxjUwDbLl/b8a12UBgqqCZK63hsPOqCxmy7dR/ubNJbWuDYTB1jDx3A2MMHYhN075hbZ7JAI2buhlpsqAz6CzqweOfn3gmaBB1gjJsEQ1G3JI9Luk1jq1bKHd9qh4WhHnv6qNV4wi6GrTNg7z5Gh6s4ZXl7jr8+r9b2Q1u859CvtIDNHstOKdDX7iZVbbbDGDcJgqJuSR6TSGFjdps+HNl+aZtzxESYlzkspu4SdDEcEP+Y9B2PHlr4fy/ukPzuFIDoCVj3gvlKQI0bW4cOY9wkDIq6JXlMIiUx5rAwlEmsK2VnyX6DXCUmS/mxmfqCuHZyh+SUJFJFSNOdQpQLilvKYHS4ahzzikHHKhHr3mEREgR96hHIY7OAuMcc5mX282CXnRK2Xd5IYrb6riuDDpYvG4hUpdEtZWDr9W7llJOWYdvla31rubTil/xsLaMQxbveKuSmc+MmeMP8/Vm+KyTZgTN1EgnTDHvm+OLCJdPdgTcef2ymHrnrkTtLdvcThVdm6xgdrmL8qvVLZuyDzsCSBhsmuW8t8mWTHPUKcdC58b62YtBBpezk5q6QZAdaGiOQxwp2SYx5YqqGbY8capthl51SoPgE2R1t8Voco26zGnIOJqZqvgXPvPtetXV34H7i7OdKCEBLY+zkdfFREmM2uU/cZKbJ7hglFu2Wzof+AAAKVklEQVSUBM5A+ypLbwjC787BGZC2FZouQecgqKyAd9+m4l0uSfVdJSQMiroleaxgl+SYTQJ9bKZuvIiEJTdLIgvhhvEr12P8qvWhSV6/kMb4VesxfuV6Y/LRdA5MrpaSSNu+w9wqWf/bIMWFiVJLirT4KI4x2yYLWxOMY5vXYOzhA0Yv+bxq20pJm/CFKRk8OlzF6q27fWPkfufAdF7mVdu2X7U4/iz/bZDiwpm6JUVafBTHmKMUumpNbp5yknke0Un/07ACa1HOweBJ/sfj916b468MOrkrAEfyD0XdkiIuPuoGv7CHyQPeKopBC3CijMs2X2B7Dm6bOIjXj/uEXgbEd1zekgHeCLtTErz2xolc5WBIMWD4xZI4enZ2SqcOll6P+b3r34qd+2ptPmzvSlK/sIV3cVIQJoeKqSUfEH4OHnjyBd99zc+3h15at93aSLp1H6+/eaLNHeQ3vm7JoyOLJEuopVFE/gbAFgD/BsBuVX1v8/nfAvA1AOcDeBbAjar63bAd5tnSmAZ+lQHDrIOtn03qC28a1/vPr+Kxp48a99nN8Zg+30qnFQyDLIp3b9kQ+byZYvlxVljs9lySfGFrabSdqX8LwMc9zz0AYCWATwD4GICHRGSlqr4SaaQkkCAHS9AXN+kmwqZxPfb00cDSvd3ePYTVXek0X1ASMTpaOjlvvegi1OnfBik2oaKuqh8XkVVoEXURGQawHsCXVPUeEZlFY9Z+ZfORxESnDhbbL3yns/lunDXdlC4I2r4gWly+lWsuOBP3P/G872udCKWpJECcOZg8OrJI8nQaU1/dfHSzPr9oPp7d3XCIl05nfDZf+G5m82n1swyyUio6vwu5c7RRcsAk7N7z6b0Ybjp3qC3sdNcV6xKNd7OnKPEjLveLm/z3vX8VkRtEZFJEJo8eNdfbJu106mCxsfJ1szgpLTdQUN2VqC3nvNw5am5b13re/Jw39z/xfJvTBUDk0sZRyKMjiyRPp6J+pPl4RvOx6nl+Cap6r6qOqOrI0JC5Mw5pp9PyuTZf+G5DKGmUIh4druLaC1e2CXtcYmZz3mzqqfdiRWkey0GT5AkNv4jIpQDe0fzvmSLyEQDfB/AzAB8QkUNoJEpfBbAzqYHmmW5dKJ3EoG0Skt3evqdVivjO0XUYOes047F1c75tzpttzLoXse08loMmyWITUx8D8O7mz+cB+CqA6wF8EMB9AD4H4DkAV6vqdBKDzDNJu1CCCPvC9yKZ56UTwTV9xu9znZxvv+0HOXhsSyQwtk3SwMb98p6Al383vqEUkyzbzuJcnGQj1p0Krs1n3P37iW3Q+e5kTDYNOuK6OHJxEYkKywQkTNZtZ619Ssc2r8H4nsORa5XYLtnvJDFr85nW/Zswne9OxuQXy77uwpWxx7bzWO6ZpA/LBCRMXmxn3YSJbO9GOrnA2XzGJnFpOt+dXnR7EcvO8l0eyS6cqSdMXmxn3dgbbYWxk6qRNp+xuesxne8sV9/M+l0eySYU9YTJqu3MW7bWFLqwERBbYezkAmfzmTABXjFoLhaWxYuu+7sxVWXKwgWHZBeGX3pA1mxnfqEWgf/KMZOAtCbwTi07cEqypPmFnzB2kpi1+UxQ4rLslHD7ZWu72r7puN33Rj2mIMIKlqV9wSHZh42nM0IvXQ6mmblX2E0V//yExxkQ/MbJyzA9Uzcum0/ywtbqfnGLc4U1me5kH37HDUHbBa3Tu7Ggu6a4j4fki7irNJIE6bWX3RRSUTSEI0yI/eLv9XnF4EnLMPXpS1Lx5qeVuKzPt0+Kuklmmn43AgR65wlxoahngF67HEyOnGqlbCUcYQm8oro2oiQoO01m5sUtRbILE6UZoNcuh26Tg2GJ0V4dj02P0jiJIqydinAWE7ckX1DUM0CvbXXdOnLChKcXx5PGwhy/43YGBE5paXmxbkQ4q24pkh+YKM0AeWxLFpTY7cXxmBKKtiGkTkna/UKICSZKc0SaTa07JSgx2YvjsW0CEvcYTMed5d8V6S8o6hkha172bkn6eMISimlWxyQkTRhTJ7kkLK7fTdkDQvIMZ+okUeKsn95KWIiHdVNIv0JRJ4mRZP109/+m7dDvTfoVhl9IYiRVP90G+r1Jv8KZOkmMpOqn25BHRxEhcUBRJ4nRSQgkzrBJ0RxFhNjA8AtJjKTqpxNCzHCmThIjqfrphBAzLBNACCE5wLZMAMMvhBBSICjqhBBSICjqhBBSICjqhBBSICjqhBBSIHrufhGRowCe6+lOo/MWAL9KexA9ol+OlcdZLPrxOM9S1aGwD/Rc1POAiEzaWIeKQL8cK4+zWPA4zTD8QgghBYKiTgghBYKi7s+9aQ+gh/TLsfI4iwWP0wBj6oQQUiA4UyeEkAJBUfcgIieLyGERURH5YtrjSQoRebZ5jO6//WmPKQlEpCIi3xCRaRF5TUR+kPaY4kZE/tjzu3T/rUp7bHEjIjc1/3bfFJEjInJj2mNKAhH5TyLyjIjMisgeEbEuU0pRb+fTAM5IexA94gcArmn++2TKY0mKrwO4FsDXANwE4J/SHU4ifB+Lv8c/AnAcwD8DqKU5qLgRkbcB+DyAeQCfAOAA+BsROTPVgcWMiIwAuA+N398nAbwHwJdtP8966i2IyHkAbkZD2P8q5eH0giMAdqvqq2kPJAlE5GwA7wPwTQC3AphT1fvSHVX8qOoRNH6XEJErAZwE4OuqWk91YPHjTkJrAP4XgOvRWJzzRmojSoZ3AxAAX1HVb4rINQDeKyL/WlX/JezDnKk3EZEBNK6O9wD4ScrD6RUfAvBrEfmliHw47cEkwG83H38HwOsAXheRv0xxPL3go2jMZAvnDlHVwwC2AtgI4GkAwwBuUNWjqQ4sfn7ZfPwPInIugLehIfKrbD5MUV/kejRO2jcAuPGrU0UkdFluTvkqgKuxeLv+FRFZne6QYmd58/EUAFsAPA7gz0XkD9IbUnKIyDkAfh/Ad1T12ZSHEzvN7+KNAPYDGAVwAMAXRaRo4dIH0fhb/VMA/weNOy/A8o6Eor7ImQCG0PhDub/53HUA7kptRAmiqn+hqg+r6v0AdgAoAXh7ysOKm2ebj/+oqrvQ+LIAwDnpDCdxPorGjM46/pozNqEx4dqlqn8HYBeA3wTwu6mOKmZU9U0AFwHYAOAdAJ5EQ9D/n83nGVNf5EEAP2/+vBbANgDfQQG/ICKyDsBnAfwDGn8DHwIwC+BgmuNKgJ+icUy/LyJ/gsbd2Bwas6BCISInAfhjAM8D+B/pjiYxXFG7TkReQiMBDgD/N6XxJIKIlAB8DsAUGqHDPwDwOVWdtfk8Rb2Jqj4F4CkAEBG3KtozqrovvVElxq/QmJl/BsAgGsf9KVV9MdVRxYyqajPJdB+AL6AheB9S1Z8HfzKXXIHGneZ/UdX5tAeTBKo6KSK3oBGCuQfAiwD+TFUPpDuy2FE0kqUfRSMX9EUA/9n2w1xRSgghBYIxdUIIKRAUdUIIKRAUdUIIKRAUdUIIKRAUdUIIKRAUdUIIKRAUdUIIKRAUdUIIKRD/H+X8LwPDRAohAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_rm_and_price():\n",
    "    plt.scatter(X[:,5], y)\n",
    "draw_rm_and_price()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x183b0145710>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_rm = X[:,5]\n",
    "k = random.randint(-100,100)\n",
    "b = random.randint(-100,100)\n",
    "price_by_random_k_and_b = [price(r, k, b) for r in X_rm]\n",
    "\n",
    "draw_rm_and_price()\n",
    "plt.scatter(X_rm, price_by_random_k_and_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,y_hat): # to evaluate the performance\n",
    "    return sum(((y_i - y_hat_i) ** 2 for y_i, y_hat_i in zip(list(y),list(y_hat)))) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 9,get best_k : 53.135509874430554 best_b: -40.9333268333299, and the loss is 74153.5336318384\n",
      "When time is : 19,get best_k : 52.13550987443054 best_b: -41.933326833329915, and the loss is 70223.13569910025\n",
      "When time is : 29,get best_k : 51.135509874430525 best_b: -42.93332683332993, and the loss is 66399.8549531093\n",
      "When time is : 39,get best_k : 50.13550987443051 best_b: -43.93332683332994, and the loss is 62683.691393865316\n",
      "When time is : 49,get best_k : 49.1355098744305 best_b: -44.93332683332996, and the loss is 59074.64502136837\n",
      "When time is : 59,get best_k : 48.13550987443048 best_b: -45.93332683332997, and the loss is 55572.71583561848\n",
      "When time is : 69,get best_k : 47.13550987443047 best_b: -46.933326833329986, and the loss is 52177.903836615544\n",
      "When time is : 79,get best_k : 46.135509874430454 best_b: -47.93332683333, and the loss is 48890.2090243598\n",
      "When time is : 89,get best_k : 45.13550987443044 best_b: -48.933326833330014, and the loss is 45709.63139885095\n",
      "When time is : 99,get best_k : 44.135509874430426 best_b: -49.93332683333003, and the loss is 42636.1709600892\n",
      "When time is : 109,get best_k : 43.13550987443041 best_b: -50.93332683333004, and the loss is 39669.82770807452\n",
      "When time is : 119,get best_k : 42.1355098744304 best_b: -51.93332683333006, and the loss is 36810.601642806854\n",
      "When time is : 129,get best_k : 41.13550987443038 best_b: -52.93332683333007, and the loss is 34058.4927642862\n",
      "When time is : 139,get best_k : 40.13550987443037 best_b: -53.933326833330085, and the loss is 31413.501072512638\n",
      "When time is : 149,get best_k : 39.135509874430355 best_b: -54.9333268333301, and the loss is 28875.62656748608\n",
      "When time is : 159,get best_k : 38.13550987443034 best_b: -55.93332683333011, and the loss is 26444.869249206524\n",
      "When time is : 169,get best_k : 37.135509874430326 best_b: -56.93332683333013, and the loss is 24121.229117674062\n",
      "When time is : 179,get best_k : 36.13550987443031 best_b: -57.93332683333014, and the loss is 21904.706172888626\n",
      "When time is : 189,get best_k : 35.1355098744303 best_b: -58.933326833330156, and the loss is 19795.300414850237\n",
      "When time is : 199,get best_k : 34.135509874430284 best_b: -59.93332683333017, and the loss is 17793.011843558852\n",
      "When time is : 209,get best_k : 33.13550987443027 best_b: -60.933326833330185, and the loss is 15897.840459014547\n",
      "When time is : 219,get best_k : 32.135509874430255 best_b: -61.9333268333302, and the loss is 14109.78626121724\n",
      "When time is : 229,get best_k : 31.13550987443024 best_b: -62.93332683333021, and the loss is 12428.849250166997\n",
      "When time is : 239,get best_k : 30.135509874430227 best_b: -63.93332683333023, and the loss is 10855.029425863786\n",
      "When time is : 249,get best_k : 29.135509874430213 best_b: -64.93332683333017, and the loss is 9388.326788307633\n",
      "When time is : 259,get best_k : 28.1355098744302 best_b: -65.93332683333011, and the loss is 8028.741337498516\n",
      "When time is : 269,get best_k : 27.135509874430184 best_b: -66.93332683333006, and the loss is 6776.273073436432\n",
      "When time is : 279,get best_k : 26.13550987443017 best_b: -67.93332683333, and the loss is 5630.921996121384\n",
      "When time is : 289,get best_k : 25.135509874430156 best_b: -68.93332683332994, and the loss is 4592.688105553372\n",
      "When time is : 299,get best_k : 24.13550987443014 best_b: -69.93332683332989, and the loss is 3661.5714017324003\n",
      "When time is : 309,get best_k : 23.135509874430127 best_b: -70.93332683332983, and the loss is 2837.571884658462\n",
      "When time is : 319,get best_k : 22.135509874430113 best_b: -71.93332683332977, and the loss is 2120.6895543315627\n",
      "When time is : 329,get best_k : 21.1355098744301 best_b: -72.93332683332972, and the loss is 1510.9244107516952\n",
      "When time is : 339,get best_k : 20.135509874430085 best_b: -73.93332683332966, and the loss is 1008.276453918868\n",
      "When time is : 349,get best_k : 19.13550987443007 best_b: -74.9333268333296, and the loss is 612.745683833077\n",
      "When time is : 359,get best_k : 18.135509874430056 best_b: -75.93332683332955, and the loss is 324.33210049432216\n",
      "When time is : 369,get best_k : 17.135509874430042 best_b: -76.93332683332949, and the loss is 143.03570390260418\n",
      "When time is : 379,get best_k : 16.135509874430028 best_b: -77.93332683332943, and the loss is 68.85649405792277\n"
     ]
    }
   ],
   "source": [
    "trying_time = 2000\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "direction = [\n",
    "    (+1,+1),\n",
    "    (+1,-1),\n",
    "    (-1,+1),\n",
    "    (-1,-1)\n",
    "]\n",
    "\n",
    "best_k = random.random() * 200 - 100\n",
    "best_b = random.random() * 200 - 100\n",
    "\n",
    "scalar = 0.1\n",
    "\n",
    "update_time = 0\n",
    "\n",
    "next_direction = random.choice(direction)\n",
    "\n",
    "for i in range(trying_time):\n",
    "    k_direction,b_direction = next_direction\n",
    "    \n",
    "    current_k, current_b = best_k + k_direction * scalar, best_b + b_direction * scalar\n",
    "    \n",
    "    price_by_k_and_b = [price(r,current_k,current_b) for r in X_rm]\n",
    "    \n",
    "    current_loss = loss(y, price_by_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        best_k, best_b = current_k, current_b\n",
    "        \n",
    "        update_time += 1\n",
    "        \n",
    "        if update_time % 10 == 0:\n",
    "            print('When time is : {},get best_k : {} best_b: {}, and the loss is {}'.format(i,best_k,best_b,min_loss))\n",
    "    else:\n",
    "        next_direction = random.choice(direction)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_k(x, y, y_hat):\n",
    "    n = len(y)\n",
    "    \n",
    "    gradient = 0\n",
    "    \n",
    "    for x_i, y_i, y_hat_i in zip(list(x), list(y), list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i) * x_i\n",
    "        \n",
    "    return -2 / n * gradient\n",
    "\n",
    "def partial_b(y, y_hat):\n",
    "    n = len(y)\n",
    "    \n",
    "    gradient = 0\n",
    "    \n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        gradient += (y_i - y_hat_i)\n",
    "    \n",
    "    return -2 / n * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 0, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43429.73058686752\n",
      "When time is : 50, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 19097.7537536141\n",
      "When time is : 100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 8412.456869993708\n",
      "When time is : 150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 3720.0484181010343\n",
      "When time is : 200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 1659.3944946550155\n",
      "When time is : 250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 754.4657239722088\n",
      "When time is : 300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 357.06932927753576\n",
      "When time is : 350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 182.55387829930956\n",
      "When time is : 400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 105.91575977011617\n",
      "When time is : 450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 72.2601055869181\n",
      "When time is : 500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 57.48003984830551\n",
      "When time is : 550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 50.98911821424084\n",
      "When time is : 600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 48.138343269078355\n",
      "When time is : 650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 46.88612519506878\n",
      "When time is : 700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 46.3359074637106\n",
      "When time is : 750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 46.09397063056335\n",
      "When time is : 800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.987414274949195\n",
      "When time is : 850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.9403098241327\n",
      "When time is : 900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.919313529516785\n",
      "When time is : 950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.90978260866529\n",
      "When time is : 1000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.905286738449114\n",
      "When time is : 1050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.90300206651156\n",
      "When time is : 1100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.90168850863975\n",
      "When time is : 1150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.900801486474016\n",
      "When time is : 1200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.900101850447854\n",
      "When time is : 1250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.899484578906076\n",
      "When time is : 1300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.898903551963926\n",
      "When time is : 1350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89833851622852\n",
      "When time is : 1400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.8977805774805\n",
      "When time is : 1450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89722582983866\n",
      "When time is : 1500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89667255803192\n",
      "When time is : 1550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89612000878766\n",
      "When time is : 1600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.8955678512909\n",
      "When time is : 1650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89501594024786\n",
      "When time is : 1700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89446421183521\n",
      "When time is : 1750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89391263800737\n",
      "When time is : 1800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89336120643024\n",
      "When time is : 1850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89280991166972\n",
      "When time is : 1900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.892258751321314\n",
      "When time is : 1950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 45.89170772431127\n"
     ]
    }
   ],
   "source": [
    "trying_times = 2000\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 1e-04\n",
    "\n",
    "update_time = 0\n",
    "\n",
    "for i in range(trying_times):\n",
    "    price_by_k_and_b = [price(r,current_k,current_b) for r in X_rm]\n",
    "    \n",
    "    current_loss = loss(y, price_by_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "        if i % 50 == 0: \n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(i, best_k, best_b, min_loss))\n",
    "    \n",
    "    k_gradient = partial_k(X_rm, y, price_by_k_and_b)\n",
    "    b_gradient = partial_b(y, price_by_k_and_b)\n",
    "    \n",
    "    current_k = current_k - k_gradient * learning_rate\n",
    "    current_b = current_b - b_gradient * learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 0, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 3534.128426572056\n",
      "When time is : 50, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.57625390254946\n",
      "When time is : 100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.55306807945024\n",
      "When time is : 150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.53043322613516\n",
      "When time is : 200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.50833624978894\n",
      "When time is : 250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.48676436872338\n",
      "When time is : 300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.46570510498463\n",
      "When time is : 350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.44514627713494\n",
      "When time is : 400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.42507599320702\n",
      "When time is : 450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.405482643824655\n",
      "When time is : 500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.38635489548807\n",
      "When time is : 550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.36768168401778\n",
      "When time is : 600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.349452208154794\n",
      "When time is : 650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.33165592331292\n",
      "When time is : 700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.314282535479045\n",
      "When time is : 750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.29732199525931\n",
      "When time is : 800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.28076449206547\n",
      "When time is : 850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.264600448440554\n",
      "When time is : 900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.24882051451881\n",
      "When time is : 950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.23341556261732\n",
      "When time is : 1000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.21837668195642\n",
      "When time is : 1050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.203695173505125\n",
      "When time is : 1100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.189362544949425\n",
      "When time is : 1150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.1753705057802\n",
      "When time is : 1200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.16171096249724\n",
      "When time is : 1250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.148376013928186\n",
      "When time is : 1300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.13535794665793\n",
      "When time is : 1350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.122649230566715\n",
      "When time is : 1400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.110242514474976\n",
      "When time is : 1450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.09813062189059\n",
      "When time is : 1500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.086306546858154\n",
      "When time is : 1550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.074763449906214\n",
      "When time is : 1600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.06349465409122\n",
      "When time is : 1650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.05249364113525\n",
      "When time is : 1700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.04175404765564\n",
      "When time is : 1750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.03126966148434\n",
      "When time is : 1800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.021034418074144\n",
      "When time is : 1850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.01104239699117\n",
      "When time is : 1900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 44.001287818490084\n",
      "When time is : 1950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.99176504017095\n",
      "When time is : 2000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.98246855371528\n",
      "When time is : 2050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.97339298170008\n",
      "When time is : 2100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.9645330744871\n",
      "When time is : 2150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.95588370718665\n",
      "When time is : 2200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.9474398766927\n",
      "When time is : 2250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.93919669878905\n",
      "When time is : 2300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.93114940532444\n",
      "When time is : 2350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.9232933414541\n",
      "When time is : 2400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.91562396294735\n",
      "When time is : 2450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.908136833559105\n",
      "When time is : 2500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.90082762246367\n",
      "When time is : 2550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.89369210174975\n",
      "When time is : 2600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.88672614397482\n",
      "When time is : 2650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.87992571977771\n",
      "When time is : 2700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.873286895547785\n",
      "When time is : 2750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.86680583114975\n",
      "When time is : 2800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.86047877770218\n",
      "When time is : 2850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.85430207540915\n",
      "When time is : 2900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.84827215144336\n",
      "When time is : 2950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.84238551787929\n",
      "When time is : 3000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.83663876967582\n",
      "When time is : 3050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.8310285827065\n",
      "When time is : 3100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.82555171183689\n",
      "When time is : 3150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.82020498904738\n",
      "When time is : 3200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.81498532160057\n",
      "When time is : 3250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.809889690252724\n",
      "When time is : 3300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.80491514750684\n",
      "When time is : 3350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.800058815907924\n",
      "When time is : 3400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.7953178863787\n",
      "When time is : 3450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.79068961659462\n",
      "When time is : 3500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.78617132939741\n",
      "When time is : 3550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.78176041124685\n",
      "When time is : 3600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.777454310708805\n",
      "When time is : 3650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.77325053697945\n",
      "When time is : 3700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.76914665844447\n",
      "When time is : 3750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.76514030127245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 3800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.761229148042005\n",
      "When time is : 3850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.75741093640097\n",
      "When time is : 3900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.753683457758086\n",
      "When time is : 3950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.75004455600522\n",
      "When time is : 4000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.746492126270425\n",
      "When time is : 4050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.743024113700216\n",
      "When time is : 4100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.73963851227102\n",
      "When time is : 4150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.73633336362891\n",
      "When time is : 4200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.73310675595674\n",
      "When time is : 4250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.72995682286814\n",
      "When time is : 4300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.726881742328345\n",
      "When time is : 4350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.723879735599866\n",
      "When time is : 4400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.72094906621366\n",
      "When time is : 4450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.71808803896498\n",
      "When time is : 4500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.71529499893234\n",
      "When time is : 4550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.71256833052076\n",
      "When time is : 4600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.70990645652688\n",
      "When time is : 4650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.70730783722675\n",
      "When time is : 4700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.70477096948529\n",
      "When time is : 4750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.70229438588672\n",
      "When time is : 4800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.69987665388568\n",
      "When time is : 4850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.69751637497887\n",
      "When time is : 4900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.69521218389583\n",
      "When time is : 4950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.692962747809354\n",
      "When time is : 5000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.69076676556451\n",
      "When time is : 5050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.68862296692589\n",
      "When time is : 5100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.68653011184312\n",
      "When time is : 5150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.68448698973329\n",
      "When time is : 5200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.68249241878093\n",
      "When time is : 5250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.68054524525422\n",
      "When time is : 5300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.67864434283785\n",
      "When time is : 5350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.67678861198121\n",
      "When time is : 5400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.674976979262716\n",
      "When time is : 5450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6732083967687\n",
      "When time is : 5500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.671481841487136\n",
      "When time is : 5550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6697963147163\n",
      "When time is : 5600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.66815084148671\n",
      "When time is : 5650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.66654446999726\n",
      "When time is : 5700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.66497627106478\n",
      "When time is : 5750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.66344533758641\n",
      "When time is : 5800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.661950784015076\n",
      "When time is : 5850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.66049174584705\n",
      "When time is : 5900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.65906737912203\n",
      "When time is : 5950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.65767685993499\n",
      "When time is : 6000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.656319383959435\n",
      "When time is : 6050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.65499416598228\n",
      "When time is : 6100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.653700439449786\n",
      "When time is : 6150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.652437456023726\n",
      "When time is : 6200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.651204485149\n",
      "When time is : 6250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.65000081363072\n",
      "When time is : 6300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.648825745222\n",
      "When time is : 6350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6476786002208\n",
      "When time is : 6400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.64655871507708\n",
      "When time is : 6450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.645465442008955\n",
      "When time is : 6500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.64439814862774\n",
      "When time is : 6550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.64335621757258\n",
      "When time is : 6600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.64233904615292\n",
      "When time is : 6650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6413460460001\n",
      "When time is : 6700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.64037664272702\n",
      "When time is : 6750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63943027559592\n",
      "When time is : 6800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.638506397193886\n",
      "When time is : 6850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.637604473116376\n",
      "When time is : 6900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.636723981657916\n",
      "When time is : 6950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63586441351051\n",
      "When time is : 7000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63502527146896\n",
      "When time is : 7050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6342060701432\n",
      "When time is : 7100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63340633567771\n",
      "When time is : 7150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63262560547714\n",
      "When time is : 7200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63186342793907\n",
      "When time is : 7250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6311193621925\n",
      "When time is : 7300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.63039297784304\n",
      "When time is : 7350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62968385472365\n",
      "When time is : 7400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.628991582651985\n",
      "When time is : 7450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62831576119298\n",
      "When time is : 7500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.627655999427034\n",
      "When time is : 7550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.627011915724204\n",
      "When time is : 7600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6263831375233\n",
      "When time is : 7650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.625769301116215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 7700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62517005143793\n",
      "When time is : 7750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.624585041860776\n",
      "When time is : 7800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.624013933994085\n",
      "When time is : 7850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.623456397488546\n",
      "When time is : 7900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62291210984488\n",
      "When time is : 7950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62238075622757\n",
      "When time is : 8000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62186202928246\n",
      "When time is : 8050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62135562895909\n",
      "When time is : 8100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62086126233738\n",
      "When time is : 8150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.62037864345782\n",
      "When time is : 8200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61990749315619\n",
      "When time is : 8250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61944753890223\n",
      "When time is : 8300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.618998514641724\n",
      "When time is : 8350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.618560160642986\n",
      "When time is : 8400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61813222334611\n",
      "When time is : 8450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61771445521683\n",
      "When time is : 8500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.617306614602946\n",
      "When time is : 8550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.616908465594776\n",
      "When time is : 8600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61651977788849\n",
      "When time is : 8650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.616140326653145\n",
      "When time is : 8700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.615769892400586\n",
      "When time is : 8750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61540826085811\n",
      "When time is : 8800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61505522284501\n",
      "When time is : 8850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61471057415148\n",
      "When time is : 8900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61437411542021\n",
      "When time is : 8950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61404565203133\n",
      "When time is : 9000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61372499398977\n",
      "When time is : 9050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.613411955815444\n",
      "When time is : 9100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6131063564356\n",
      "When time is : 9150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61280801908065\n",
      "When time is : 9200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.612516771181554\n",
      "When time is : 9250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61223244426995\n",
      "When time is : 9300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61195487388091\n",
      "When time is : 9350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61168389945774\n",
      "When time is : 9400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.611419364259056\n",
      "When time is : 9450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.611161115268104\n",
      "When time is : 9500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61090900310438\n",
      "When time is : 9550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61066288193715\n",
      "When time is : 9600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61042260940108\n",
      "When time is : 9650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.61018804651373\n",
      "When time is : 9700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60995905759565\n",
      "When time is : 9750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60973551019128\n",
      "When time is : 9800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60951727499272\n",
      "When time is : 9850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60930422576495\n",
      "When time is : 9900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60909623927253\n",
      "When time is : 9950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60889319520861\n",
      "When time is : 10000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60869497612528\n",
      "When time is : 10050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60850146736526\n",
      "When time is : 10100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60831255699624\n",
      "When time is : 10150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60812813574564\n",
      "When time is : 10200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60794809693752\n",
      "When time is : 10250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60777233643101\n",
      "When time is : 10300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60760075255981\n",
      "When time is : 10350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.607433246073626\n",
      "When time is : 10400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.607269720080744\n",
      "When time is : 10450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60711007999183\n",
      "When time is : 10500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60695423346522\n",
      "When time is : 10550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60680209035371\n",
      "When time is : 10600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.606653562652234\n",
      "When time is : 10650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60650856444695\n",
      "When time is : 10700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.606367011865764\n",
      "When time is : 10750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60622882302952\n",
      "When time is : 10800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.606093918004795\n",
      "When time is : 10850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60596221875768\n",
      "When time is : 10900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60583364910855\n",
      "When time is : 10950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60570813468814\n",
      "When time is : 11000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60558560289437\n",
      "When time is : 11050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6054659828503\n",
      "When time is : 11100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.605349205363616\n",
      "When time is : 11150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60523520288581\n",
      "When time is : 11200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60512390947387\n",
      "When time is : 11250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.605015260751614\n",
      "When time is : 11300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60490919387263\n",
      "When time is : 11350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604805647484156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 11400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60470456169114\n",
      "When time is : 11450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60460587802184\n",
      "When time is : 11500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604509539394265\n",
      "When time is : 11550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604415490082495\n",
      "When time is : 11600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604323675685166\n",
      "When time is : 11650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604234043093385\n",
      "When time is : 11700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604146540460434\n",
      "When time is : 11750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.604061117171675\n",
      "When time is : 11800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60397772381527\n",
      "When time is : 11850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60389631215345\n",
      "When time is : 11900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60381683509468\n",
      "When time is : 11950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6037392466667\n",
      "When time is : 12000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60366350198946\n",
      "When time is : 12050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60358955724963\n",
      "When time is : 12100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.603517369674684\n",
      "When time is : 12150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.603446897508945\n",
      "When time is : 12200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60337809998868\n",
      "When time is : 12250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.603310937318966\n",
      "When time is : 12300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60324537065038\n",
      "When time is : 12350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60318136205695\n",
      "When time is : 12400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60311887451368\n",
      "When time is : 12450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6030578718756\n",
      "When time is : 12500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602998318856514\n",
      "When time is : 12550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602940181008826\n",
      "When time is : 12600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60288342470364\n",
      "When time is : 12650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60282801711081\n",
      "When time is : 12700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60277392618076\n",
      "When time is : 12750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60272112062536\n",
      "When time is : 12800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60266956989984\n",
      "When time is : 12850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602619244185576\n",
      "When time is : 12900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60257011437218\n",
      "When time is : 12950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602522152041324\n",
      "When time is : 13000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60247532944981\n",
      "When time is : 13050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602429619513785\n",
      "When time is : 13100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60238499579293\n",
      "When time is : 13150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602341432475356\n",
      "When time is : 13200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60229890436244\n",
      "When time is : 13250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602257386854305\n",
      "When time is : 13300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60221685593589\n",
      "When time is : 13350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60217728816245\n",
      "When time is : 13400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602138660646744\n",
      "When time is : 13450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60210095104507\n",
      "When time is : 13500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60206413754494\n",
      "When time is : 13550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.602028198852075\n",
      "When time is : 13600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60199311417822\n",
      "When time is : 13650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60195886322911\n",
      "When time is : 13700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60192542619283\n",
      "When time is : 13750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60189278372815\n",
      "When time is : 13800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60186091695345\n",
      "When time is : 13850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60182980743591\n",
      "When time is : 13900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601799437180695\n",
      "When time is : 13950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60176978862047\n",
      "When time is : 14000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60174084460543\n",
      "When time is : 14050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60171258839338\n",
      "When time is : 14100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60168500363983\n",
      "When time is : 14150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60165807438885\n",
      "When time is : 14200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601631785063496\n",
      "When time is : 14250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60160612045718\n",
      "When time is : 14300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60158106572459\n",
      "When time is : 14350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601556606372924\n",
      "When time is : 14400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60153272825434\n",
      "When time is : 14450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601509417556606\n",
      "When time is : 14500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60148666079613\n",
      "When time is : 14550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601464444809515\n",
      "When time is : 14600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6014427567462\n",
      "When time is : 14650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60142158406112\n",
      "When time is : 14700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60140091450719\n",
      "When time is : 14750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60138073612843\n",
      "When time is : 14800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601361037252765\n",
      "When time is : 14850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60134180648591\n",
      "When time is : 14900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601323032703945\n",
      "When time is : 14950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60130470504741\n",
      "When time is : 15000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601286812915056\n",
      "When time is : 15050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60126934595731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 15100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60125229407073\n",
      "When time is : 15150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601235647391874\n",
      "When time is : 15200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60121939629166\n",
      "When time is : 15250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60120353136985\n",
      "When time is : 15300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60118804344977\n",
      "When time is : 15350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60117292357241\n",
      "When time is : 15400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60115816299199\n",
      "When time is : 15450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60114375317056\n",
      "When time is : 15500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60112968577283\n",
      "When time is : 15550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60111595266175\n",
      "When time is : 15600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60110254589359\n",
      "When time is : 15650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60108945771338\n",
      "When time is : 15700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60107668055049\n",
      "When time is : 15750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601064207014076\n",
      "When time is : 15800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601052029889054\n",
      "When time is : 15850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.601040142131716\n",
      "When time is : 15900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60102853686574\n",
      "When time is : 15950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60101720737825\n",
      "When time is : 16000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60100614711587\n",
      "When time is : 16050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60099534968089\n",
      "When time is : 16100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60098480882772\n",
      "When time is : 16150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60097451845918\n",
      "When time is : 16200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600964472622884\n",
      "When time is : 16250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60095466550799\n",
      "When time is : 16300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600945091441766\n",
      "When time is : 16350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60093574488612\n",
      "When time is : 16400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60092662043475\n",
      "When time is : 16450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60091771280968\n",
      "When time is : 16500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600909016858445\n",
      "When time is : 16550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600900527551026\n",
      "When time is : 16600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600892239976886\n",
      "When time is : 16650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600884149342136\n",
      "When time is : 16700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600876250967005\n",
      "When time is : 16750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60086854028259\n",
      "When time is : 16800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600861012828915\n",
      "When time is : 16850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60085366425171\n",
      "When time is : 16900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600846490300384\n",
      "When time is : 16950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60083948682525\n",
      "When time is : 17000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600832649775185\n",
      "When time is : 17050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60082597519549\n",
      "When time is : 17100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60081945922527\n",
      "When time is : 17150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600813098095486\n",
      "When time is : 17200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60080688812657\n",
      "When time is : 17250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600800825726516\n",
      "When time is : 17300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60079490738869\n",
      "When time is : 17350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6007891296895\n",
      "When time is : 17400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60078348928709\n",
      "When time is : 17450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60077798291879\n",
      "When time is : 17500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60077260739954\n",
      "When time is : 17550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60076735961991\n",
      "When time is : 17600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60076223654442\n",
      "When time is : 17650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60075723520969\n",
      "When time is : 17700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60075235272281\n",
      "When time is : 17750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600747586259445\n",
      "When time is : 17800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60074293306268\n",
      "When time is : 17850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60073839044078\n",
      "When time is : 17900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60073395576625\n",
      "When time is : 17950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60072962647386\n",
      "When time is : 18000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60072540005938\n",
      "When time is : 18050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60072127407807\n",
      "When time is : 18100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60071724614344\n",
      "When time is : 18150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600713313925425\n",
      "When time is : 18200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60070947514959\n",
      "When time is : 18250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60070572759546\n",
      "When time is : 18300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60070206909525\n",
      "When time is : 18350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60069849753273\n",
      "When time is : 18400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6006950108421\n",
      "When time is : 18450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60069160700644\n",
      "When time is : 18500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60068828405688\n",
      "When time is : 18550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60068504007128\n",
      "When time is : 18600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60068187317318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 18650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60067878153086\n",
      "When time is : 18700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60067576335587\n",
      "When time is : 18750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60067281690251\n",
      "When time is : 18800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60066994046622\n",
      "When time is : 18850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60066713238338\n",
      "When time is : 18900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60066439102963\n",
      "When time is : 18950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60066171481928\n",
      "When time is : 19000, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600659102204276\n",
      "When time is : 19050, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60065655167343\n",
      "When time is : 19100, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60065406175142\n",
      "When time is : 19150, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60065163099796\n",
      "When time is : 19200, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600649258006996\n",
      "When time is : 19250, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600646941406\n",
      "When time is : 19300, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600644679854824\n",
      "When time is : 19350, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60064247204541\n",
      "When time is : 19400, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60064031670069\n",
      "When time is : 19450, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60063821257388\n",
      "When time is : 19500, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60063615844788\n",
      "When time is : 19550, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600634153134536\n",
      "When time is : 19600, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60063219547389\n",
      "When time is : 19650, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60063028433353\n",
      "When time is : 19700, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60062841860807\n",
      "When time is : 19750, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.600626597218266\n",
      "When time is : 19800, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60062481911047\n",
      "When time is : 19850, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.6006230832563\n",
      "When time is : 19900, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60062138865162\n",
      "When time is : 19950, get best_k: 15.935509874430027 best_b: -78.13332683332942, and the loss is: 43.60061973431608\n"
     ]
    }
   ],
   "source": [
    "trying_times = 20000\n",
    "\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "min_loss = float('inf') \n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 1e-02\n",
    "\n",
    "\n",
    "update_time = 0\n",
    "\n",
    "for i in range(trying_times):\n",
    "    \n",
    "    price_by_k_and_b = [price(r, current_k, current_b) for r in X_rm]\n",
    "    \n",
    "    current_loss = loss(y, price_by_k_and_b)\n",
    "\n",
    "    if current_loss < min_loss: # performance became better\n",
    "        min_loss = current_loss\n",
    "        \n",
    "        if i % 50 == 0: \n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(i, best_k, best_b, min_loss))\n",
    "\n",
    "    k_gradient = partial_k(X_rm, y, price_by_k_and_b)\n",
    "    \n",
    "    b_gradient = partial_b(y, price_by_k_and_b)\n",
    "    \n",
    "    current_k = current_k + (-1 * k_gradient) * learning_rate\n",
    "\n",
    "    current_b = current_b + (-1 * b_gradient) * learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_price = [1, 5, 8, 9, 10, 17, 17, 20, 24, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "price = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(original_price):\n",
    "    price[i + 1] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {1: 1,\n",
       "             2: 5,\n",
       "             3: 8,\n",
       "             4: 9,\n",
       "             5: 10,\n",
       "             6: 17,\n",
       "             7: 17,\n",
       "             8: 20,\n",
       "             9: 24,\n",
       "             10: 30,\n",
       "             11: 35})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "called_time = defaultdict(int)\n",
    "\n",
    "def get_call_times(f):\n",
    "    result = f()\n",
    "    print('function: {} called once! '.format(f.__name__))\n",
    "    called_time[f.__name__] += 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_funcion_1(): print('I am function 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am function 1\n",
      "function: some_funcion_1 called once! \n"
     ]
    }
   ],
   "source": [
    "get_call_times(some_funcion_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'some_funcion_1': 1})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "called_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_time_with_arg = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f):\n",
    "    call_time_with_arg = defaultdict(int)\n",
    "    @wraps(f)\n",
    "    def wrap(n):\n",
    "        result = None\n",
    "        if n in call_time_with_arg:\n",
    "            result = call_time_with_arg[n]\n",
    "        else:\n",
    "            result = f(n)\n",
    "            call_time_with_arg[n] = result\n",
    "        return result\n",
    "    \n",
    "    return wrap\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memo\n",
    "def r(n):\n",
    "    max_price,max_split = max([(price[n],0)]+[(r(i) + r(n-i),i) for i in range(1,n)], key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}\n",
    "@memo\n",
    "def r(n):\n",
    "\n",
    "    max_price, max_split = max(\n",
    "        [(price[n], 0)] + [(r(i) + r(n-i), i) for i in range(1, n)], key=lambda x: x[0]\n",
    "    )\n",
    "\n",
    "    solution[n] = (n - max_split, max_split)\n",
    "    \n",
    "    return max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_solution(n):\n",
    "    left_split, right_split = solution[n]\n",
    "    if right_split == 0:\n",
    "        return [left_split]\n",
    "    else:\n",
    "        parse_solution(left_split)+parse_solution(right_split)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "called_time_with_arg = defaultdict(int)\n",
    "\n",
    "def get_call_time(f):\n",
    "    \"\"\"@param f is a function\"\"\"\n",
    "    @wraps(f)\n",
    "    def wrap(n):\n",
    "        \"\"\"Haha I am warp\"\"\"\n",
    "       # print('I can count')\n",
    "        result = f(n)\n",
    "        called_time_with_arg[(f.__name__, n)] += 1\n",
    "        return result\n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(f): \n",
    "    memo.already_computed = {}\n",
    "    @wraps(f)\n",
    "    def _wrap(arg):\n",
    "        result = None\n",
    "        \n",
    "        if arg in memo.already_computed: \n",
    "            result = memo.already_computed[arg]\n",
    "        else:\n",
    "            result = f(arg)\n",
    "            memo.already_computed[arg] = result\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    return _wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "@get_call_time\n",
    "@memo\n",
    "def r(n):\n",
    "    \"\"\"\n",
    "    Args: n is the iron length\n",
    "    Return: the max revenue \n",
    "    \"\"\"\n",
    "    max_price, max_split = max(\n",
    "        [(price[n], 0)] + [(r(i) + r(n-i), i) for i in range(1, n)], key=lambda x: x[0]\n",
    "    )\n",
    "\n",
    "    solution[n] = (n - max_split, max_split)\n",
    "    \n",
    "    return max_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('r', 1), 26),\n",
       " (('r', 2), 24),\n",
       " (('r', 3), 22),\n",
       " (('r', 4), 20),\n",
       " (('r', 5), 18),\n",
       " (('r', 6), 16),\n",
       " (('r', 7), 14),\n",
       " (('r', 8), 12),\n",
       " (('r', 9), 10),\n",
       " (('r', 10), 8),\n",
       " (('r', 11), 6),\n",
       " (('r', 12), 4),\n",
       " (('r', 13), 2),\n",
       " (('r', 14), 2)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(called_time_with_arg).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: change loss function from $loss = \\frac{1}{n}\\sum{(y_i - \\hat(y_i))^2}$ to $loss = \\frac{1}{n}\\sum{|y_i - \\hat{y_i}|}$, and using your mathmatical knowledge to get the right partial formual. Implemen the gradient descent code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y,y_hat):\n",
    "    return sum([np.abs(y_i - y_hat_i) for y_i,y_hat_i in zip(list(y),list(y_hat))]) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $loss = \\frac{1}{n}\\sum{|y_i - \\hat{y_i}|}$\n",
    "# $ gradient_k = \\frac{1}{n}\\sum{x}$    , $ k >= \\frac{y-b}{x}$\n",
    "# $ gradient_k = \\frac{1}{n}\\sum{-x}$    ,$ k < \\frac{y-b}{x}$\n",
    "# $ gradient_b = \\frac{1}{n}\\sum{1}$    ,$ b > y-kx $\n",
    "# $ gradient_b = \\frac{1}{n}\\sum{-1}$    , $ b < y-kx$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_k(k, x, y, b):\n",
    "    n=len(y)\n",
    "    gradient = 0\n",
    "    for i,x_i in enumerate(x):\n",
    "        border = ((y[i] - b) / x_i)\n",
    "        if k >= border:\n",
    "            gradient +=  x_i\n",
    "        else:\n",
    "            gradient += -1 * x_i\n",
    "    return gradient / n\n",
    "    \n",
    "def partial_b(b, x, y, k):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for i,x_i in enumerate(x):\n",
    "        border = y[i] - k * x_i\n",
    "        if b >= border:\n",
    "            gradient += 1\n",
    "        else:\n",
    "            gradient += -1\n",
    "    return gradient / n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "X,y =data['data'], data['target']\n",
    "X_rm = X[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(rm, k, b):\n",
    "    \"\"\"f(x) = k * x + b\"\"\"\n",
    "    return k * rm + b  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is : 50, get best_k: 14.549340586210054 best_b: 86.35243750746142, and the loss is: 155.2569173447393\n",
      "When time is : 100, get best_k: 14.235108866842435 best_b: 86.30243750746118, and the loss is: 153.23208587560467\n",
      "When time is : 150, get best_k: 13.920877147474815 best_b: 86.25243750746094, and the loss is: 151.20725440647004\n",
      "When time is : 200, get best_k: 13.606645428107196 best_b: 86.2024375074607, and the loss is: 149.1824229373354\n",
      "When time is : 250, get best_k: 13.292413708739577 best_b: 86.15243750746046, and the loss is: 147.15759146820068\n",
      "When time is : 300, get best_k: 12.978181989371958 best_b: 86.10243750746022, and the loss is: 145.13275999906594\n",
      "When time is : 350, get best_k: 12.663950270004339 best_b: 86.05243750745998, and the loss is: 143.1079285299314\n",
      "When time is : 400, get best_k: 12.34971855063672 best_b: 86.00243750745975, and the loss is: 141.08309706079666\n",
      "When time is : 450, get best_k: 12.0354868312691 best_b: 85.9524375074595, and the loss is: 139.05826559166204\n",
      "When time is : 500, get best_k: 11.721255111901481 best_b: 85.90243750745927, and the loss is: 137.03343412252752\n",
      "When time is : 550, get best_k: 11.407023392533862 best_b: 85.85243750745903, and the loss is: 135.0086026533928\n",
      "When time is : 600, get best_k: 11.092791673166243 best_b: 85.80243750745879, and the loss is: 132.98377118425822\n",
      "When time is : 650, get best_k: 10.778559953798624 best_b: 85.75243750745855, and the loss is: 130.95893971512348\n",
      "When time is : 700, get best_k: 10.464328234431004 best_b: 85.70243750745831, and the loss is: 128.93410824598894\n",
      "When time is : 750, get best_k: 10.150096515063385 best_b: 85.65243750745807, and the loss is: 126.90927677685414\n",
      "When time is : 800, get best_k: 9.835864795695766 best_b: 85.60243750745784, and the loss is: 124.88444530771957\n",
      "When time is : 850, get best_k: 9.521633076328147 best_b: 85.5524375074576, and the loss is: 122.859613838585\n",
      "When time is : 900, get best_k: 9.207401356960528 best_b: 85.50243750745736, and the loss is: 120.8347823694504\n",
      "When time is : 950, get best_k: 8.893169637592909 best_b: 85.45243750745712, and the loss is: 118.80995090031561\n",
      "When time is : 1000, get best_k: 8.57893791822529 best_b: 85.40243750745688, and the loss is: 116.78511943118095\n",
      "When time is : 1050, get best_k: 8.26470619885767 best_b: 85.35243750745664, and the loss is: 114.7602879620464\n",
      "When time is : 1100, get best_k: 7.950474479490058 best_b: 85.3024375074564, and the loss is: 112.7354564929117\n",
      "When time is : 1150, get best_k: 7.636242760122483 best_b: 85.25243750745616, and the loss is: 110.71062502377748\n",
      "When time is : 1200, get best_k: 7.322011040754909 best_b: 85.20243750745593, and the loss is: 108.68579355464296\n",
      "When time is : 1250, get best_k: 7.007779321387334 best_b: 85.15243750745569, and the loss is: 106.66096208550869\n",
      "When time is : 1300, get best_k: 6.693547602019759 best_b: 85.10243750745545, and the loss is: 104.63613061637419\n",
      "When time is : 1350, get best_k: 6.379315882652184 best_b: 85.05243750745521, and the loss is: 102.61129914723983\n",
      "When time is : 1400, get best_k: 6.0650841632846095 best_b: 85.00243750745497, and the loss is: 100.5864676781055\n",
      "When time is : 1450, get best_k: 5.750852443917035 best_b: 84.95243750745473, and the loss is: 98.56163620897104\n",
      "When time is : 1500, get best_k: 5.43662072454946 best_b: 84.9024375074545, and the loss is: 96.53680473983674\n",
      "When time is : 1550, get best_k: 5.122389005181885 best_b: 84.85243750745425, and the loss is: 94.51197327070234\n",
      "When time is : 1600, get best_k: 4.8081572858143105 best_b: 84.80243750745402, and the loss is: 92.48714180156782\n",
      "When time is : 1650, get best_k: 4.493925566446736 best_b: 84.75243750745378, and the loss is: 90.46231033243365\n",
      "When time is : 1700, get best_k: 4.179693847079161 best_b: 84.70243750745354, and the loss is: 88.43747886329925\n",
      "When time is : 1750, get best_k: 3.8654621277115764 best_b: 84.6524375074533, and the loss is: 86.4126473941648\n",
      "When time is : 1800, get best_k: 3.5512304083439794 best_b: 84.60243750745306, and the loss is: 84.38781592503022\n",
      "When time is : 1850, get best_k: 3.2369986889763824 best_b: 84.55243750745282, and the loss is: 82.3629844558958\n",
      "When time is : 1900, get best_k: 2.9227669696087855 best_b: 84.50243750745258, and the loss is: 80.33815298676119\n",
      "When time is : 1950, get best_k: 2.6085352502411885 best_b: 84.45243750745234, and the loss is: 78.31332151762672\n",
      "When time is : 2000, get best_k: 2.2943035308735915 best_b: 84.4024375074521, and the loss is: 76.2884900484921\n"
     ]
    }
   ],
   "source": [
    "trying_time = 2000\n",
    "\n",
    "min_loss = float('inf')\n",
    "\n",
    "current_k = random.random() * 200 - 100\n",
    "current_b = random.random() * 200 - 100\n",
    "\n",
    "learning_rate = 0.001\n",
    "update_time = 0\n",
    "\n",
    "# while True:\n",
    "for _ in range(trying_time):\n",
    "    price_by_k_and_b = [price(r, current_k, current_b) for r in X_rm]\n",
    "    current_loss = loss(y,price_by_k_and_b)\n",
    "    \n",
    "    if current_loss < min_loss:\n",
    "        min_loss = current_loss\n",
    "   \n",
    "        best_k, best_b = current_k, current_b \n",
    "        \n",
    "        update_time += 1\n",
    "        if update_time % 50 == 0:\n",
    "            print('When time is : {}, get best_k: {} best_b: {}, and the loss is: {}'.format(update_time, current_k, current_b, current_loss))\n",
    "    \n",
    "    k_gradient = partial_k(current_k, X_rm, y,current_b)\n",
    "    b_gradient = partial_b(current_b, X_rm, y,current_k)\n",
    "    \n",
    "    current_k = current_k - k_gradient * learning_rate\n",
    "    current_b = current_b - b_gradient * learning_rate\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Finish the Solution Parse Part of Edit-Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2**10)\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    \n",
    "    if len(string1) == 0: return len(string2)\n",
    "    if len(string2) == 0: return len(string1)\n",
    "    \n",
    "    #都不为空，则返回最后一位\n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    \n",
    "    #'ABCDE', 'ABCCEF'\n",
    "    candidates = [\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),  # string 1 delete tail\n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  # string 1 add tail of string2\n",
    "    ]\n",
    "\n",
    "    if tail_s1 == tail_s2:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "\n",
    "    candidates.append(both_forward)\n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0])\n",
    "    \n",
    "    solution[(string1, string2)] = operation \n",
    "    \n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Choose 1 - 2 books to keep reading: \n",
    "\n",
    "+ SICP, Structure and Interpretation of Computer Programming. \n",
    "+ Introduction to Algorithms \n",
    "+ Artificial Intelligence A Modern Approach (3rd Edition) \n",
    "+ Code Complete 2 \n",
    "+ Programming Pearls \n",
    "+ Deep Learning\n",
    "+ 黑客与画家\n",
    "+ 数学之美\n",
    "+ Fluent Python\n",
    "+ Hands on Tensorflow\n",
    "+ Conference: NIPS_ ICML_ ICLR_ ACL_ AAAI\n",
    "\n",
    "> most books you may find in our github: https://github.com/Computing-Intelligence/References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5-1: review machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we use Derivative / Gredient to fit a target function?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:有利于根据导数反方向，快速搜索到损失函数的极值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. In the words 'Gredient Descent', what's the Gredient and what's the Descent?¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:梯度即导数。下降是沿着导数的反方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. What's the advantages of the 3rd gradient descent method compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:搜索极值速度快、时间短、易找到极值、"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the simple words to describe: What's the machine leanring.¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:让机器不断拟合大量数据，探索数据规律，不断获取新的知识，完善自身性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Answer following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Why do we need dynamic programming? What's the difference of dynamic programming and previous talked `search` problme? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动态规划能记录子问题产生的值，无需重复计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Why do we still need dynamic programming? Why not we train a machine learning to fit a function which could get the `right` answer based on inputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于重复的且具有最优结构的子问题求解，动态规划有着较强的能力，且求解时间少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Can you catch up at least 3 problems which could solved by Dynamic Programming? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "路径搜索、交通工具换乘、切分利润问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can you catch up at least 3 problems wich could sloved by Edit Distance? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较词之间的相似性、论文查重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Please summarize the three main features of Dynamic Programming, and make a concise explain for each feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、重复子问题\n",
    "2.每个子问题存在最有子结构\n",
    "3、对后续的值无影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What's the disadvantages of Dynamic Programming? (You may need search by yourself in Internet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、没有统一的标准模型\n",
    "2、数值方法求解时存在维度灾难"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 Preparation of Project-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using python Flask or Bottle to finish your first simple web app:\n",
    "> https://bottlepy.org/\n",
    "\n",
    "2. Learn what's the SQL, and try some simple SQL operations:\n",
    "> https://www.w3schools.com/sql/sql_intro.asp\n",
    "\n",
    "3. Learn what's the HTML ( *ONLY* need to know the basic things)\n",
    "> https://getbootstrap.com/; https://www.w3schools.com/html/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optinal) Finish the k-person-salesman problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = [random.randint(-100, 100) for _ in range(20)]\n",
    "longitude = [random.randint(-100, 100) for _ in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(latitudes, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo(func):\n",
    "    memo.already_computed = {}\n",
    "    def warp(satrt,end):\n",
    "        result = None\n",
    "        if str(start) and str(end) in memo.already_computed:\n",
    "            try:\n",
    "                result = memo.already_computed[str(start)+str(end)]\n",
    "            except:\n",
    "                result = memo.already_computed[str(end) + str(start)]\n",
    "        else:\n",
    "            result = func(start,end)\n",
    "            memo.already_computed[str(start) + str(end)] = func(start,end)\n",
    "        return result\n",
    "    return warp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(start,end):\n",
    "    x1, y1 = start\n",
    "    x2, y2 = end\n",
    "    return np.sqrt(sum([(x1-x2) ** 2+(y1-y2)**2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #野蛮搜索savage seach\n",
    "# def search_route(initial,map_spot):\n",
    "#     \"\"\"\n",
    "#     :params initial      ：str      initial spot\n",
    "#     :params map_spot     : dict     the spot need  be connection\n",
    "    \n",
    "#     \"\"\"\n",
    "#     pathes = [[initial,0]]\n",
    "#     route = []\n",
    "#     while pathes:\n",
    "        \n",
    "#         path = pathes.pop()\n",
    "#         fronter = path[-2] \n",
    "#         between_distance = path.pop(-1)\n",
    "#         for spot in map_spot.keys():\n",
    "#             if spot not in path:\n",
    "#                 between_distance += get_distance(map_spot[fronter], map_spot[spot])\n",
    "#                 new_path = path + [spot] + [between_distance] \n",
    "                \n",
    "# #                 print(new_path)\n",
    "#                 if len(new_path) == len(map_spot)+1:\n",
    "#                     route.append(new_path)\n",
    "#                     print(route)\n",
    "#                 else:\n",
    "#                     pathes.append(new_path)\n",
    "                    \n",
    "#     route = sorted(route,key = lambda x: x[-1]) \n",
    "#     return route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdot['A'] = [10,10]\n",
    "search_route('A', mapdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个初始点 𝑃, 已经 𝑘个车辆，如何从该点出发，经这 k 个车辆经过所以的点全部一次，而且所走过的路程最短?\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_p = (-50, 10)\n",
    "chosen_p2 = (1, 30)\n",
    "chosen_p3 = (99, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(latitudes, longitude)\n",
    "plt.scatter([chosen_p[0]], [chosen_p[1]], color='r')\n",
    "plt.scatter([chosen_p2[0]], [chosen_p2[1]], color='r')\n",
    "plt.scatter([chosen_p3[0]], [chosen_p3[1]], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
